{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å®éªŒå…­ï¼šå†³ç­–æ ‘åˆ†ç±»å™¨\n",
    "- å§“åï¼šå†¯æ€ç¨‹\n",
    "- å­¦å·ï¼š2112213\n",
    "- ä¸“ä¸šï¼šè®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å®éªŒè¦æ±‚\n",
    "### æˆªæ­¢æ—¥æœŸï¼š12æœˆ15æ—¥\n",
    "ä»¥å­¦å·+å§“å(6)çš„å‘½åå½¢å¼æ‰“åŒ…å®éªŒä»£ç +å®éªŒæŠ¥å‘Šï¼Œå‘é€åˆ°é‚®ç®±18329300691@163.com\n",
    "\n",
    "### æ•°æ®é›†\n",
    "\n",
    "è¿™é‡Œä½¿ç”¨çš„æ˜¯ç»™å®šçš„æ•°æ®é›†ã€‚\n",
    "\n",
    "\n",
    "### åŸºæœ¬è¦æ±‚\n",
    "- \tåŸºäº Watermelon-train1æ•°æ®é›†ï¼ˆåªæœ‰ç¦»æ•£å±æ€§ï¼‰ï¼Œæ„é€ ID3å†³ç­–æ ‘ï¼›\n",
    "- \tåŸºäºæ„é€ çš„ ID3 å†³ç­–æ ‘ï¼Œå¯¹æ•°æ®é›† Watermelon-test1è¿›è¡Œé¢„æµ‹ï¼Œè¾“å‡ºåˆ†ç±»ç²¾åº¦ï¼›\n",
    "### ä¸­çº§è¦æ±‚\n",
    "-   å¯¹æ•°æ®é›†Watermelon-train2ï¼Œæ„é€ C4.5æˆ–è€…CARTå†³ç­–æ ‘ï¼Œè¦æ±‚å¯ä»¥å¤„ç†è¿ç»­å‹å±æ€§ï¼›\n",
    "-   å¯¹æµ‹è¯•é›†Watermelon-test2è¿›è¡Œé¢„æµ‹ï¼Œè¾“å‡ºåˆ†ç±»ç²¾åº¦ï¼›\n",
    "### é«˜çº§è¦æ±‚\n",
    "ä½¿ç”¨ä»»æ„çš„å‰ªæç®—æ³•å¯¹æ„é€ çš„å†³ç­–æ ‘ï¼ˆåŸºæœ¬è¦æ±‚å’Œä¸­çº§è¦æ±‚æ„é€ çš„æ ‘ï¼‰è¿›è¡Œå‰ªæï¼Œè§‚å¯Ÿæµ‹è¯•é›†åˆçš„åˆ†ç±»ç²¾åº¦æ˜¯å¦æœ‰æå‡ï¼Œç»™å‡ºåˆ†æè¿‡ç¨‹ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=======================================================================================================================\n",
    "\n",
    "# å¼€å§‹\n",
    "\n",
    "**ç¯å¢ƒ**ï¼špython 3.10.9+vscode 1.82.2+ä¸€äº›å¿…å¤‡çš„ç¬¬ä¸‰æ–¹åº“ï¼Œä¾‹å¦‚pandasç­‰ã€‚\n",
    "\n",
    "<span style=\"color:red\">**æ³¨æ„**</span>ï¼šæˆ‘åœ¨åæ–‡çš„ä»£ç éƒ½è¡¥å……äº†é€‚å½“çš„æ³¨é‡Šå¹¶åœ¨ä»£ç å‰è¿›è¡Œäº†é€‚å½“æ³¨é‡Šå’Œåˆ†æï¼Œæ„Ÿè°¢å­¦é•¿å­¦å§çš„æ‰¹é˜…ï¼è¾›è‹¦ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åŸºç¡€è¦æ±‚éƒ¨åˆ†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¯¼å…¥éœ€è¦çš„åŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import log\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ•°æ®è¯»å–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ç¼–å·  è‰²æ³½  æ ¹è’‚  æ•²å£°  çº¹ç† å¥½ç“œ\n",
      "0    1  é’ç»¿  èœ·ç¼©  æµŠå“  æ¸…æ™°  æ˜¯\n",
      "1    2  ä¹Œé»‘  èœ·ç¼©  æ²‰é—·  æ¸…æ™°  æ˜¯\n",
      "2    3  ä¹Œé»‘  èœ·ç¼©  æµŠå“  æ¸…æ™°  æ˜¯\n",
      "3    4  é’ç»¿  èœ·ç¼©  æ²‰é—·  æ¸…æ™°  æ˜¯\n",
      "4    5  æµ…ç™½  èœ·ç¼©  æµŠå“  æ¸…æ™°  æ˜¯\n",
      "5    6  é’ç»¿  ç¨èœ·  æµŠå“  æ¸…æ™°  æ˜¯\n",
      "6    7  ä¹Œé»‘  ç¨èœ·  æµŠå“  ç¨ç³Š  æ˜¯\n",
      "7    8  ä¹Œé»‘  ç¨èœ·  æµŠå“  æ¸…æ™°  æ˜¯\n",
      "8    9  ä¹Œé»‘  ç¨èœ·  æ²‰é—·  ç¨ç³Š  å¦\n",
      "9   10  é’ç»¿  ç¡¬æŒº  æ¸…è„†  æ¸…æ™°  å¦\n",
      "10  11  æµ…ç™½  ç¡¬æŒº  æ¸…è„†  æ¨¡ç³Š  å¦\n",
      "11  12  æµ…ç™½  èœ·ç¼©  æµŠå“  æ¨¡ç³Š  å¦\n",
      "12  13  é’ç»¿  ç¨èœ·  æµŠå“  ç¨ç³Š  å¦\n",
      "13  14  æµ…ç™½  ç¨èœ·  æ²‰é—·  ç¨ç³Š  å¦\n",
      "14  15  æµ…ç™½  èœ·ç¼©  æµŠå“  æ¨¡ç³Š  å¦\n",
      "15  16  é’ç»¿  èœ·ç¼©  æ²‰é—·  ç¨ç³Š  å¦\n"
     ]
    }
   ],
   "source": [
    "train1 = pd.read_csv(\"Watermelon-train1.csv\", encoding='gbk')\n",
    "test1 = pd.read_csv(\"Watermelon-test1.csv\", encoding='gbk')\n",
    "train2 = pd.read_csv(\"Watermelon-train2.csv\", encoding='gbk')\n",
    "test2 = pd.read_csv(\"Watermelon-test2.csv\", encoding='gbk')\n",
    "print(train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ•°æ®é¢„å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    è‰²æ³½  æ ¹è’‚  æ•²å£°  çº¹ç†  å¥½ç“œ\n",
      "0    2   0   0   2   1\n",
      "1    1   0   1   2   1\n",
      "2    1   0   0   2   1\n",
      "3    2   0   1   2   1\n",
      "4    0   0   0   2   1\n",
      "5    2   1   0   2   1\n",
      "6    1   1   0   1   1\n",
      "7    1   1   0   2   1\n",
      "8    1   1   1   1   0\n",
      "9    2   2   2   2   0\n",
      "10   0   2   2   0   0\n",
      "11   0   0   0   0   0\n",
      "12   2   1   0   1   0\n",
      "13   0   1   1   1   0\n",
      "14   0   0   0   0   0\n",
      "15   2   0   1   1   0\n",
      "    è‰²æ³½  æ ¹è’‚  æ•²å£°  çº¹ç†     å¯†åº¦  å¥½ç“œ\n",
      "0    2   0   0   2  0.697   1\n",
      "1    1   0   1   2  0.774   1\n",
      "2    1   0   0   2  0.634   1\n",
      "3    2   0   1   2  0.608   1\n",
      "4    0   0   0   2  0.556   1\n",
      "5    2   1   0   2  0.403   1\n",
      "6    1   1   0   1  0.481   1\n",
      "7    1   1   0   2  0.437   1\n",
      "8    1   1   1   1  0.666   0\n",
      "9    2   2   2   2  0.243   0\n",
      "10   0   2   2   0  0.245   0\n",
      "11   0   0   0   0  0.343   0\n",
      "12   2   1   0   1  0.639   0\n",
      "13   0   1   1   1  0.657   0\n",
      "14   1   1   0   2  0.360   0\n",
      "15   0   0   0   0  0.593   0\n",
      "16   2   0   1   1  0.719   0\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(data):\n",
    "    # åˆ é™¤ç¬¬ä¸€åˆ—-æ ‡å·åˆ—\n",
    "    data = data.drop(columns=['ç¼–å·'])\n",
    "    # å®šä¹‰æ˜ å°„å…³ç³»\n",
    "    feature_mappings = {\n",
    "        'è‰²æ³½': {'æµ…ç™½': 0, 'ä¹Œé»‘': 1, 'é’ç»¿': 2},\n",
    "        'æ ¹è’‚': {'èœ·ç¼©': 0, 'ç¨èœ·': 1, 'ç¡¬æŒº': 2},\n",
    "        'æ•²å£°': {'æµŠå“': 0, 'æ²‰é—·': 1, 'æ¸…è„†': 2},\n",
    "        'çº¹ç†': {'æ¨¡ç³Š': 0, 'ç¨ç³Š': 1, 'æ¸…æ™°': 2},\n",
    "        'å¥½ç“œ': {'æ˜¯': 1, 'å¦': 0}\n",
    "    }\n",
    "\n",
    "    # å°†ç‰¹å¾å’Œç›®æ ‡å˜é‡è¿›è¡Œè½¬æ¢\n",
    "    for column, mapping in feature_mappings.items():\n",
    "        if column in data.columns:\n",
    "            data[column] = data[column].map(mapping)\n",
    "    \n",
    "    return data\n",
    "\n",
    "train1 = preprocessing(train1)\n",
    "test1 = preprocessing(test1)\n",
    "train2 = preprocessing(train2)\n",
    "test2 = preprocessing(test2)\n",
    "print(train1)\n",
    "print(train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®ç°ID3å†³ç­–æ ‘ï¼š\n",
    "\n",
    "åœ¨ä¿¡æ¯è®ºä¸æ¦‚ç‡ç»Ÿè®¡ä¸­ï¼Œç†µæ˜¯è¡¨ç¤ºéšæœºå˜é‡ä¸ç¡®å®šæ€§çš„é‡ã€‚Xæ˜¯â¼€ä¸ªå–å€¼ä¸ºæœ‰é™ä¸ªçš„ç¦»æ•£éšæœºå˜é‡ï¼Œç†µçš„å…¬å¼å¦‚ä¸‹ï¼š\n",
    "$$ H(X)=-\\sum_{i=1}^{n} p\\left(x_{i}\\right) \\log p\\left(x_{i}\\right)$$ \n",
    "$ğ»(ğ‘‹)$å°±è¢«ç§°ä½œéšæœºå˜é‡ğ‘‹çš„ç†µï¼Œå®ƒè¡¨ç¤ºéšæœºå˜é‡ä¸ç¡®å®šçš„åº¦é‡ã€‚ç†µå–å€¼è¶Šå¤§ï¼Œéšæœºå˜é‡ä¸ç¡®å®šæ€§è¶Šå¤§ã€‚å½“éšæœºå˜é‡ä¸ºå‡åŒ€åˆ†å¸ƒæ—¶ï¼Œç†µæœ€å¤§ã€‚å½“æŸä¸€çŠ¶æ€æ¦‚ç‡å–å€¼ä¸º1æ—¶ï¼Œç†µçš„å€¼ä¸ºé›¶ã€‚\n",
    "\n",
    "æ¡ä»¶ç†µè¡¨ç¤ºåœ¨å·²çŸ¥éšæœºå˜é‡ğ‘‹çš„æ¡ä»¶ä¸‹éšæœºå˜é‡ğ‘Œçš„ä¸ç¡®å®šæ€§ï¼Œå®šä¹‰ä¸ºç»™å®šğ‘‹æ¡ä»¶ä¸‹ğ‘Œçš„æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒçš„ç†µå¯¹ğ‘‹çš„æ•°å­¦æœŸæœ›:\n",
    "$$H(Y \\mid X)=\\sum_{x} p(x) H(Y \\mid X=x) =-\\sum_{x} p(x) \\sum_{y} p(y \\mid x) \\log p(y \\mid x)$$\n",
    "\n",
    "ç‰¹å¾ğ´å¯¹æ•°æ®é›†ğ·çš„**ä¿¡æ¯å¢ç›Š**å°±æ˜¯ç†µ$ğ»(ğ·)$ä¸æ¡ä»¶ç†µ$ğ»(ğ·|ğ´)$ä¹‹å·®:\n",
    "$$ğ»(ğ·)âˆ’ğ»(ğ·âˆ£ğ´)$$\n",
    "\n",
    "è¡¨ç¤ºå·²çŸ¥ç‰¹å¾ğ´çš„ä¿¡æ¯è€Œä½¿å¾—æ•°æ®é›†ğ·çš„ä¿¡æ¯ä¸ç¡®å®šå‡å°‘çš„ç¨‹åº¦ã€‚ä¿¡æ¯å¢ç›Šè¶Šå¤§çš„ç‰¹å¾ä»£è¡¨å…¶å…·æœ‰æ›´å¼ºçš„åˆ†ç±»èƒ½åŠ›ï¼Œæ‰€ä»¥æˆ‘ä»¬å°±è¦**é€‰æ‹©èƒ½å¤Ÿä½¿æ•°æ®çš„ä¸ç¡®å®šç¨‹åº¦å‡å°‘æœ€å¤šçš„ç‰¹å¾**ï¼Œä¹Ÿå°±æ˜¯ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾ã€‚\n",
    "\n",
    "#### å†³ç­–æ ‘çš„ç”Ÿæˆ\n",
    "\n",
    "ä»æ ¹èŠ‚ç‚¹å¼€å§‹ï¼Œè®¡ç®—æ‰€æœ‰å¯èƒ½ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šï¼Œé€‰æ‹©ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾ä½œä¸ºåˆ’åˆ†è¯¥èŠ‚ç‚¹çš„ç‰¹å¾ï¼Œæ ¹æ®è¯¥ç‰¹å¾çš„ä¸åŒå–å€¼å»ºç«‹å­èŠ‚ç‚¹ï¼›\n",
    "åœ¨å¯¹å­èŠ‚ç‚¹é€’å½’åœ°è°ƒç”¨ä»¥ä¸Šæ–¹æ³•ï¼Œç›´åˆ°è¾¾åˆ°åœæ­¢æ¡ä»¶ï¼Œå¾—åˆ°â¼€ä¸ªå†³ç­–æ ‘ã€‚\n",
    "\n",
    "#### å†³ç­–æ ‘çš„åœæ­¢æ¡ä»¶ï¼š\n",
    "\n",
    "  1. å½“å‰ç»“ç‚¹æ‰€æœ‰æ ·æœ¬éƒ½å±äºåŒâ¼€ç±»åˆ«ï¼›\n",
    "  2. å½“å‰ç»“ç‚¹çš„æ‰€æœ‰å±æ€§å€¼éƒ½ç›¸åŒï¼Œæ²¡æœ‰å‰©ä½™å±æ€§å¯ç”¨æ¥è¿›ä¸€æ­¥åˆ’åˆ†æ ·æœ¬ï¼›\n",
    "  3. è¾¾åˆ°æœ€å¤§æ ‘æ·±ï¼›\n",
    "  4. è¾¾åˆ°å¶å­ç»“ç‚¹çš„æœ€å°æ ·æœ¬æ•°ï¼›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—ä¿¡æ¯ç†µ\n",
    "def calculate_entropy(dataframe, target_column='å¥½ç“œ'):\n",
    "    \n",
    "    num_entries = len(dataframe)\n",
    "    label_counts = dataframe[target_column].value_counts()\n",
    "\n",
    "    entropy = 0.0\n",
    "    for count in label_counts:\n",
    "        probability = count / num_entries\n",
    "        entropy -= probability * log(probability, 2)\n",
    "\n",
    "    return entropy\n",
    "\n",
    "\n",
    "# ä»ä¸€ä¸ªæ•°æ®é›†ä¸­åˆ’åˆ†å‡ºä¸€ä¸ªå­æ•°æ®é›†ï¼Œè¿™ä¸ªå­æ•°æ®é›†åªåŒ…å«åœ¨æŒ‡å®šç‰¹å¾ä¸Šå…·æœ‰ç‰¹å®šå€¼çš„æ•°æ®è¡Œï¼Œå¹¶ä¸”åœ¨è¿”å›çš„æ•°æ®ç‚¹ä¸­ä¸åŒ…æ‹¬è¿™ä¸ªç‰¹å®šç‰¹å¾è½´çš„å€¼ã€‚\n",
    "def split_dataframe(dataframe, feature, value):\n",
    "\n",
    "    # ç­›é€‰å‡ºç‰¹å¾åˆ—ç¬¦åˆæŒ‡å®šå€¼çš„è¡Œ\n",
    "    filtered_df = dataframe[dataframe[feature] == value]\n",
    "\n",
    "    # åˆ é™¤è¯¥ç‰¹å¾åˆ—\n",
    "    subdataframe = filtered_df.drop(columns=[feature])\n",
    "\n",
    "    return subdataframe\n",
    "\n",
    "\n",
    "# å°†éå†æ¯ä¸ªç‰¹å¾åˆ—ï¼Œè®¡ç®—æ¯ä¸ªç‰¹å¾çš„ä¿¡æ¯å¢ç›Šï¼Œæœ€åè¿”å›å…·æœ‰æœ€å¤§ä¿¡æ¯å¢ç›Šçš„ç‰¹å¾åˆ—çš„åç§°ã€‚\n",
    "def id3_choose_best_feature_to_split(dataframe, target_column='å¥½ç“œ'):\n",
    "    \n",
    "    base_entropy = calculate_entropy(dataframe, target_column)\n",
    "    best_info_gain = 0.0\n",
    "    best_feature = ''\n",
    "\n",
    "    for feature in dataframe.columns:\n",
    "        if feature == target_column:\n",
    "            continue  # Skip the target column\n",
    "        unique_vals = dataframe[feature].unique()\n",
    "        new_entropy = 0.0\n",
    "        \n",
    "        for value in unique_vals:\n",
    "            sub_df = split_dataframe(dataframe, feature, value)\n",
    "            probability = len(sub_df) / float(len(dataframe))\n",
    "            new_entropy += probability * calculate_entropy(sub_df, target_column)\n",
    "        \n",
    "        info_gain = base_entropy - new_entropy\n",
    "        print(f\"ID3: Information Gain for feature '{feature}': {info_gain:.3f}\")\n",
    "        if info_gain > best_info_gain:\n",
    "            best_info_gain = info_gain\n",
    "            best_feature = feature\n",
    "\n",
    "    return best_feature\n",
    "\n",
    "\n",
    "# å½“æ•°æ®é›†çš„æ‰€æœ‰ç‰¹å¾éƒ½å·²å¤„ç†ï¼Œä½†ç±»åˆ«æ ‡ç­¾ä»ä¸å”¯ä¸€æ—¶ï¼Œä½¿ç”¨å¤šæ•°è¡¨å†³çš„æ–¹æ³•å†³å®šå¶å­èŠ‚ç‚¹çš„åˆ†ç±»ã€‚\n",
    "def majority_vote(labels):\n",
    "    label_count = {}\n",
    "    for label in labels:\n",
    "        if label not in label_count:\n",
    "            label_count[label] = 0\n",
    "        label_count[label] += 1\n",
    "\n",
    "    sorted_label_count = sorted(label_count.items(), key=lambda item: item[1], reverse=True)\n",
    "    return sorted_label_count[0][0]\n",
    "\n",
    "\n",
    "# å®ç°åŸºäºID3å†³ç­–æ ‘çš„æ„å»º\n",
    "def ID3_createTree(dataset, labels):\n",
    "    classList = dataset.iloc[:, -1].tolist()  # å‡è®¾æœ€åä¸€åˆ—ä¸ºç±»åˆ«åˆ—\n",
    "\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "\n",
    "    if len(dataset.columns) == 1:\n",
    "        return majority_vote(classList)\n",
    "\n",
    "    bestFeatLabel = id3_choose_best_feature_to_split(dataset, dataset.columns[-1])\n",
    "    ID3Tree = {bestFeatLabel: {}}\n",
    "\n",
    "    # åˆ é™¤å·²ä½¿ç”¨çš„ç‰¹å¾\n",
    "    remaining_features = [lbl for lbl in dataset.columns if lbl != bestFeatLabel and lbl != dataset.columns[-1]]\n",
    "\n",
    "    uniqueVals = dataset[bestFeatLabel].unique()\n",
    "    for value in uniqueVals:\n",
    "        reducedDataset = split_dataframe(dataset, bestFeatLabel, value)\n",
    "        ID3Tree[bestFeatLabel][value] = ID3_createTree(reducedDataset, remaining_features)\n",
    "\n",
    "    return ID3Tree\n",
    "\n",
    "\n",
    "# å•ä¸ªæ•°æ®å®ä¾‹ï¼ˆDataFrame çš„ä¸€è¡Œï¼‰è¿›è¡Œåˆ†ç±»\n",
    "def classify(decision_tree, feature_labels, test_vector):\n",
    "    if not isinstance(decision_tree, dict):\n",
    "        # å¦‚æœdecision_treeä¸æ˜¯å­—å…¸ï¼Œé‚£ä¹ˆå®ƒæ˜¯ä¸€ä¸ªå¶èŠ‚ç‚¹çš„å€¼\n",
    "        return decision_tree\n",
    "\n",
    "    root_feature = list(decision_tree.keys())[0]\n",
    "    sub_tree = decision_tree[root_feature]\n",
    "\n",
    "    if root_feature not in feature_labels:\n",
    "        return None  # å¦‚æœç‰¹å¾æ ‡ç­¾ä¸åœ¨feature_labelsä¸­ï¼Œè¿”å›None\n",
    "\n",
    "    feature_index = feature_labels.index(root_feature)\n",
    "    \n",
    "    if feature_index >= len(test_vector):\n",
    "        return None  # å¦‚æœç‰¹å¾ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œè¿”å›None\n",
    "\n",
    "    feature_value = test_vector[feature_index]\n",
    "\n",
    "    if isinstance(sub_tree, dict) and feature_value in sub_tree:\n",
    "        # åªæœ‰å½“sub_treeæ˜¯å­—å…¸æ—¶æ‰æ‰§è¡Œæ¯”è¾ƒ\n",
    "        if isinstance(sub_tree[feature_value], dict):\n",
    "            return classify(sub_tree[feature_value], feature_labels, test_vector)\n",
    "        else:\n",
    "            return sub_tree[feature_value]\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# å¯¹ä¸€ä¸ªDataFrameçš„æ¯è¡Œè¿›è¡Œåˆ†ç±»ã€‚\n",
    "def classifytest(decision_tree, feature_labels, test_data):\n",
    "    classification_results = []\n",
    "    for _, row in test_data.iterrows():\n",
    "        classification_results.append(classify(decision_tree, feature_labels, row))\n",
    "    return classification_results\n",
    "\n",
    "\n",
    "# è®¡ç®—å‡†ç¡®ç‡\n",
    "def calculate_accuracy(predicted_labels, true_labels):\n",
    "    if len(true_labels) == 0:\n",
    "        return 0  # å¦‚æœæ²¡æœ‰çœŸå®æ ‡ç­¾ï¼Œè¿”å›0ä½œä¸ºå‡†ç¡®ç‡\n",
    "    correct = sum(p == t for p, t in zip(predicted_labels, true_labels))\n",
    "    accuracy = correct / len(true_labels)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID3: Information Gain for feature 'è‰²æ³½': 0.174\n",
      "ID3: Information Gain for feature 'æ ¹è’‚': 0.148\n",
      "ID3: Information Gain for feature 'æ•²å£°': 0.180\n",
      "ID3: Information Gain for feature 'çº¹ç†': 0.503\n",
      "ID3: Information Gain for feature 'è‰²æ³½': 0.138\n",
      "ID3: Information Gain for feature 'æ ¹è’‚': 0.544\n",
      "ID3: Information Gain for feature 'æ•²å£°': 0.544\n",
      "ID3: Information Gain for feature 'è‰²æ³½': 0.322\n",
      "ID3: Information Gain for feature 'æ ¹è’‚': 0.073\n",
      "ID3: Information Gain for feature 'æ•²å£°': 0.322\n",
      "ID3: Information Gain for feature 'æ ¹è’‚': 0.000\n",
      "ID3: Information Gain for feature 'æ•²å£°': 1.000\n",
      "Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "# æ„å»ºå†³ç­–æ ‘\n",
    "feature_labels = list(train1.columns)  # æ‰€æœ‰ç‰¹å¾çš„åˆ—å\n",
    "decision_tree1 = ID3_createTree(train1, feature_labels)\n",
    "\n",
    "# å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œåˆ†ç±»\n",
    "predicted_labels1 = classifytest(decision_tree1, feature_labels, test1)\n",
    "\n",
    "# è®¡ç®—å‡†ç¡®ç‡\n",
    "true_labels = test1.iloc[:, -1].tolist()  # çœŸå®æ ‡ç­¾\n",
    "accuracy = calculate_accuracy(predicted_labels1, true_labels)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸­çº§è¦æ±‚éƒ¨åˆ†\n",
    "\n",
    "è¿™é‡Œæˆ‘é€‰æ‹©ç”¨åˆ°çš„æ˜¯C4.5ç®—æ³•ï¼Œä¸‹é¢è¿›è¡Œä¸€ä¸‹ç®€å•çš„ä»‹ç»ï¼š\n",
    "\n",
    "- C4.5ç®—æ³•ä¸ID3ç®—æ³•ç›¸ä¼¼ï¼Œå…¶å¯¹ID3ç®—æ³•è¿›è¡Œäº†æ”¹è¿›ã€‚\n",
    "- ä¿¡æ¯å¢ç›Šä½œä¸ºåˆ’åˆ†å‡†åˆ™å­˜åœ¨çš„é—®é¢˜ï¼š\n",
    "\n",
    "     ä¿¡æ¯å¢ç›Šåå‘äºé€‰æ‹©å–å€¼è¾ƒå¤šçš„ç‰¹å¾è¿›è¡Œåˆ’åˆ†ã€‚â½å¦‚å­¦å·è¿™ä¸ªç‰¹å¾ï¼Œæ¯ä¸ªå­¦ç”Ÿéƒ½æœ‰ä¸€ä¸ªä¸åŒçš„å­¦å·ï¼Œå¦‚æœæ ¹æ®å­¦å·å¯¹æ ·æœ¬è¿›è¡Œåˆ†ç±»ï¼Œåˆ™æ¯ä¸ªå­¦ç”Ÿéƒ½å±äºä¸åŒçš„ç±»åˆ«ï¼Œè¿™æ ·æ˜¯æ²¡æœ‰æ„ä¹‰çš„ã€‚è€ŒC4.5åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œç”¨**ä¿¡æ¯å¢ç›Šæ¯”**æ¥é€‰æ‹©ç‰¹å¾ï¼Œå¯ä»¥æ ¡æ­£è¿™ä¸ªé—®é¢˜ã€‚\n",
    "     \n",
    "- ç‰¹ç‚¹\n",
    "  - èƒ½å¤Ÿå®Œæˆå¯¹è¿ç»­å±æ€§çš„ç¦»æ•£åŒ–å¤„ç†\n",
    "  - èƒ½å¤Ÿå¯¹ä¸å®Œæ•´æ•°æ®è¿›è¡Œå¤„ç†\n",
    "  - éœ€è¦å¯¹æ•°æ®é›†è¿›è¡Œå¤šæ¬¡çš„é¡ºåºæ‰«æå’Œæ’åº\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®ç°C4.5ç®—æ³•çš„æœ€ä½³ç‰¹å¾åˆ—é€‰å–\n",
    "def C45_chooseBestFeatureToSplit(dataframe):\n",
    "    \n",
    "    base_entropy = calculate_entropy(dataframe)\n",
    "    best_info_gain_ratio = 0.0\n",
    "    best_feature = ''\n",
    "\n",
    "    for feature in dataframe.columns[:-1]:  # éå†æ‰€æœ‰ç‰¹å¾ï¼Œæ’é™¤æœ€åçš„ç±»åˆ«åˆ—\n",
    "        feat_list = dataframe[feature]\n",
    "        unique_vals = set(feat_list)  # åˆ›å»ºå”¯ä¸€çš„åˆ†ç±»æ ‡ç­¾åˆ—è¡¨\n",
    "        new_entropy = 0.0\n",
    "        IV = 0.0\n",
    "\n",
    "        for value in unique_vals:\n",
    "            sub_dataframe = split_dataframe(dataframe, feature, value)\n",
    "            p = len(sub_dataframe) / float(len(dataframe))\n",
    "            new_entropy += p * calculate_entropy(sub_dataframe)\n",
    "            IV -= p * log(p, 2) if p > 0 else 0  # é˜²æ­¢pä¸º0å¯¼è‡´çš„log(0)é”™è¯¯\n",
    "\n",
    "        info_gain = base_entropy - new_entropy\n",
    "        info_gain_ratio = info_gain / IV if IV != 0 else 0\n",
    "\n",
    "        print(f\"C4.5: Information Gain Ratio for feature '{feature}': {info_gain_ratio:.3f}\")\n",
    "        if info_gain_ratio > best_info_gain_ratio:\n",
    "            best_info_gain_ratio = info_gain_ratio\n",
    "            best_feature = feature\n",
    "\n",
    "    return best_feature\n",
    "\n",
    "# å®ç°åŸºäºC4.5å†³ç­–æ ‘çš„æ„å»º\n",
    "def C45_createTree(dataset, labels):\n",
    "    classList = dataset.iloc[:, -1].tolist()  # å‡è®¾æœ€åä¸€åˆ—ä¸ºç±»åˆ«åˆ—\n",
    "\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "\n",
    "    # å¦‚æœæ²¡æœ‰æ›´å¤šç‰¹å¾å¯ä»¥ç”¨äºè¿›ä¸€æ­¥åˆ’åˆ†\n",
    "    if len(dataset.columns) == 1:\n",
    "        return majority_vote(classList)\n",
    "\n",
    "    bestFeatLabel = C45_chooseBestFeatureToSplit(dataset)\n",
    "    C45Tree = {bestFeatLabel: {}}\n",
    "\n",
    "    # åˆ é™¤å·²ä½¿ç”¨çš„ç‰¹å¾\n",
    "    remaining_features = [lbl for lbl in labels if lbl != bestFeatLabel]\n",
    "\n",
    "    uniqueVals = dataset[bestFeatLabel].unique()\n",
    "    for value in uniqueVals:\n",
    "        reducedDataset = split_dataframe(dataset, bestFeatLabel, value)\n",
    "        C45Tree[bestFeatLabel][value] = C45_createTree(reducedDataset, remaining_features)\n",
    "\n",
    "    return C45Tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5: Information Gain Ratio for feature 'è‰²æ³½': 0.068\n",
      "C4.5: Information Gain Ratio for feature 'æ ¹è’‚': 0.102\n",
      "C4.5: Information Gain Ratio for feature 'æ•²å£°': 0.106\n",
      "C4.5: Information Gain Ratio for feature 'çº¹ç†': 0.263\n",
      "C4.5: Information Gain Ratio for feature 'å¯†åº¦': 0.244\n",
      "C4.5: Information Gain Ratio for feature 'è‰²æ³½': 0.031\n",
      "C4.5: Information Gain Ratio for feature 'æ ¹è’‚': 0.339\n",
      "C4.5: Information Gain Ratio for feature 'æ•²å£°': 0.270\n",
      "C4.5: Information Gain Ratio for feature 'å¯†åº¦': 0.241\n",
      "C4.5: Information Gain Ratio for feature 'è‰²æ³½': 0.274\n",
      "C4.5: Information Gain Ratio for feature 'æ•²å£°': 0.000\n",
      "C4.5: Information Gain Ratio for feature 'å¯†åº¦': 0.579\n",
      "C4.5: Information Gain Ratio for feature 'è‰²æ³½': 0.212\n",
      "C4.5: Information Gain Ratio for feature 'æ ¹è’‚': 0.101\n",
      "C4.5: Information Gain Ratio for feature 'æ•²å£°': 0.332\n",
      "C4.5: Information Gain Ratio for feature 'å¯†åº¦': 0.311\n",
      "C4.5: Information Gain Ratio for feature 'è‰²æ³½': 1.000\n",
      "C4.5: Information Gain Ratio for feature 'æ ¹è’‚': 0.000\n",
      "C4.5: Information Gain Ratio for feature 'å¯†åº¦': 1.000\n",
      "Accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "# æ„å»ºå†³ç­–æ ‘\n",
    "feature_labels = list(train2.columns)  # æ‰€æœ‰ç‰¹å¾çš„åˆ—å\n",
    "decision_tree2 = C45_createTree(train2, feature_labels)\n",
    "\n",
    "# å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œåˆ†ç±»\n",
    "predicted_labels2 = classifytest(decision_tree2, feature_labels, test2)\n",
    "\n",
    "# è®¡ç®—å‡†ç¡®ç‡\n",
    "true_labels2 = test2.iloc[:, -1].tolist()  # çœŸå®æ ‡ç­¾\n",
    "accuracy2 = calculate_accuracy(predicted_labels2, true_labels2)\n",
    "\n",
    "print(\"Accuracy:\", accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é«˜çº§è¦æ±‚éƒ¨åˆ†\n",
    "\n",
    "- å†³ç­–æ ‘å¾ˆå®¹æ˜“å‡ºç°**è¿‡æ‹Ÿåˆç°è±¡**ã€‚åŸå› åœ¨äºå­¦ä¹ æ—¶å®Œå…¨è€ƒè™‘çš„æ˜¯å¦‚ä½•æâ¾¼å¯¹è®­ç»ƒæ•°æ®çš„æ­£ç¡®åˆ†ç±»ä»â½½æ„å»ºå‡ºè¿‡äºå¤æ‚çš„å†³ç­–æ ‘ã€‚\n",
    "- è§£å†³è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•ç§°ä¸º**å‰ªæ**ï¼Œå³å¯¹å·²ç”Ÿæˆçš„æ ‘è¿›è¡Œç®€åŒ–ã€‚å…·ä½“åœ°ï¼Œå°±æ˜¯ä»å·²ç”Ÿæˆçš„æ ‘ä¸Šè£å‰ªæ‰â¼€äº›å­æ ‘æˆ–å¶èŠ‚ç‚¹ï¼Œå¹¶å°†å…¶æ ¹èŠ‚ç‚¹æˆ–çˆ¶èŠ‚ç‚¹ä½œä¸ºæ–°çš„å¶èŠ‚ç‚¹ã€‚ \n",
    "- å†³ç­–æ ‘çš„å‰ªæåŸºæœ¬ç­–ç•¥æœ‰**é¢„å‰ªæ (Pre-Pruning)** å’Œ **åå‰ªæ (Post-Pruning)**\n",
    "   - **é¢„å‰ªæ**ï¼šæ˜¯æ ¹æ®â¼€äº›åŸåˆ™**ææ—©çš„åœæ­¢æ ‘å¢é•¿**ï¼Œå¦‚æ ‘çš„æ·±åº¦è¾¾åˆ°ç”¨æˆ·æ‰€è¦çš„æ·±åº¦ã€èŠ‚ç‚¹ä¸­æ ·æœ¬ä¸ªæ•°å°‘äºç”¨æˆ·æŒ‡å®šä¸ªæ•°ã€ä¸çº¯åº¦æŒ‡æ ‡ä¸‹é™çš„å¹…åº¦å°äºç”¨æˆ·æŒ‡å®šçš„å¹…åº¦ç­‰ã€‚ \n",
    "   - **åå‰ªæ**ï¼šæ˜¯é€šè¿‡åœ¨å®Œå…¨ç”Ÿé•¿çš„æ ‘ä¸Šå‰ªå»åˆ†æå®ç°çš„ï¼Œé€šè¿‡åˆ é™¤èŠ‚ç‚¹çš„åˆ†æ”¯æ¥å‰ªå»æ ‘èŠ‚ç‚¹ã€‚æ˜¯åœ¨ç”Ÿæˆå†³ç­–æ ‘ä¹‹å**è‡ªåº•å‘ä¸Š**çš„å¯¹æ ‘ä¸­æ‰€æœ‰çš„éå¶ç»“ç‚¹è¿›â¾é€ä¸€è€ƒå¯Ÿ ã€‚\n",
    "\n",
    "è¿™é‡Œæˆ‘å¯¹åœ¨åŸºç¡€è¦æ±‚ä¸­å®ç°çš„ID3å†³ç­–æ ‘å’Œåœ¨ä¸­çº§è¦æ±‚ä¸­å®ç°çš„C4.5å†³ç­–æ ‘æ¥è¿›è¡Œé¢„å‰ªæå’Œåå‰ªæç­–ç•¥çš„æ·»åŠ ï¼Œå¹¶è¿›è¡Œåˆ†æã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3_createTree2(dataset, labels, test_dataset=None, pre_pruning=True, post_pruning=True):\n",
    "    classList = dataset.iloc[:, -1].tolist()  # å‡è®¾æœ€åä¸€åˆ—ä¸ºç±»åˆ«åˆ—\n",
    "\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "\n",
    "    if len(dataset.columns) == 1:\n",
    "        return majority_vote(classList)\n",
    "\n",
    "    bestFeatLabel = id3_choose_best_feature_to_split(dataset)\n",
    "    ID3Tree = {bestFeatLabel: {}}\n",
    "    \n",
    "    uniqueVals = dataset[bestFeatLabel].unique()\n",
    "\n",
    "    # é¢„å‰ªæé€»è¾‘\n",
    "    if pre_pruning and test_dataset is not None:\n",
    "        leaf = majority_vote(classList)\n",
    "        accuracy_without_split = calculate_accuracy(\n",
    "            classifytest({bestFeatLabel: leaf}, labels, test_dataset),\n",
    "            test_dataset.iloc[:, -1]\n",
    "        )\n",
    "        accuracy_with_split = 0\n",
    "        for value in uniqueVals:\n",
    "            subDataset = split_dataframe(dataset, bestFeatLabel, value)\n",
    "            subTestset = split_dataframe(test_dataset, bestFeatLabel, value)\n",
    "            if not subTestset.empty:  # ç¡®ä¿å­æµ‹è¯•é›†ä¸ä¸ºç©º\n",
    "                subTree = ID3_createTree2(subDataset, labels[:], subTestset)\n",
    "                accuracy_with_split += calculate_accuracy(\n",
    "                    classifytest({bestFeatLabel: {value: subTree}}, labels, subTestset),\n",
    "                    subTestset.iloc[:, -1]\n",
    "                )\n",
    "        if accuracy_without_split >= accuracy_with_split / len(uniqueVals):\n",
    "            print(\"å‘ç”Ÿé¢„å‰ªæå¤„ç†\")\n",
    "            return leaf\n",
    "\n",
    "    # æ„å»ºå­æ ‘\n",
    "    for value in uniqueVals:\n",
    "        subDataset = split_dataframe(dataset, bestFeatLabel, value)\n",
    "        if test_dataset is not None:  # æ£€æŸ¥test_datasetæ˜¯å¦ä¸ºNone\n",
    "            subTestset = split_dataframe(test_dataset, bestFeatLabel, value)\n",
    "            if not subTestset.empty:  # ç¡®ä¿å­æµ‹è¯•é›†ä¸ä¸ºç©º\n",
    "                subTree = ID3_createTree2(subDataset, labels[:], subTestset, pre_pruning, post_pruning)\n",
    "                accuracy_with_split += calculate_accuracy(\n",
    "                    classifytest({bestFeatLabel: {value: subTree}}, labels, subTestset),\n",
    "                    subTestset.iloc[:, -1]\n",
    "                )\n",
    "        else:\n",
    "            subTestset = None\n",
    "        ID3Tree[bestFeatLabel][value] = ID3_createTree2(subDataset, labels[:], subTestset, pre_pruning, post_pruning)\n",
    "    # åå‰ªæé€»è¾‘\n",
    "    if post_pruning and test_dataset is not None:\n",
    "        leaf = majority_vote(classList)\n",
    "        accuracy_without_split = calculate_accuracy(\n",
    "            classifytest({bestFeatLabel: leaf}, labels, test_dataset),\n",
    "            test_dataset.iloc[:, -1]\n",
    "        )\n",
    "        accuracy_with_split = calculate_accuracy(\n",
    "            classifytest(ID3Tree, labels, test_dataset),\n",
    "            test_dataset.iloc[:, -1]\n",
    "        )\n",
    "        if accuracy_without_split >= accuracy_with_split:\n",
    "            print(\"å‘ç”Ÿåå‰ªæå¤„ç†\")\n",
    "            return leaf\n",
    "\n",
    "    return ID3Tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID3: Information Gain for feature 'è‰²æ³½': 0.254\n",
      "ID3: Information Gain for feature 'æ ¹è’‚': 0.150\n",
      "ID3: Information Gain for feature 'æ•²å£°': 0.227\n",
      "ID3: Information Gain for feature 'çº¹ç†': 0.319\n",
      "ID3: Information Gain for feature 'è‰²æ³½': 0.128\n",
      "ID3: Information Gain for feature 'æ ¹è’‚': 0.592\n",
      "ID3: Information Gain for feature 'æ•²å£°': 0.592\n",
      "ID3: Information Gain for feature 'è‰²æ³½': 0.918\n",
      "ID3: Information Gain for feature 'æ ¹è’‚': 0.252\n",
      "ID3: Information Gain for feature 'æ•²å£°': 0.918\n",
      "å‘ç”Ÿé¢„å‰ªæå¤„ç†\n",
      "ID3: Information Gain for feature 'è‰²æ³½': 0.128\n",
      "ID3: Information Gain for feature 'æ ¹è’‚': 0.592\n",
      "ID3: Information Gain for feature 'æ•²å£°': 0.592\n",
      "ID3: Information Gain for feature 'è‰²æ³½': 0.128\n",
      "ID3: Information Gain for feature 'æ ¹è’‚': 0.592\n",
      "ID3: Information Gain for feature 'æ•²å£°': 0.592\n",
      "ID3: Information Gain for feature 'è‰²æ³½': 0.918\n",
      "ID3: Information Gain for feature 'æ ¹è’‚': 0.252\n",
      "ID3: Information Gain for feature 'æ•²å£°': 0.918\n",
      "å‘ç”Ÿé¢„å‰ªæå¤„ç†\n",
      "ID3: Information Gain for feature 'è‰²æ³½': 0.918\n",
      "ID3: Information Gain for feature 'æ ¹è’‚': 0.252\n",
      "ID3: Information Gain for feature 'æ•²å£°': 0.918\n",
      "å‘ç”Ÿé¢„å‰ªæå¤„ç†\n",
      "Accuracy 2.0: 0.8\n"
     ]
    }
   ],
   "source": [
    "# æ„å»ºå†³ç­–æ ‘\n",
    "feature_labels = list(train1.columns)  # æ‰€æœ‰ç‰¹å¾çš„åˆ—å\n",
    "\n",
    "# åˆ†å‰²æ•°æ®é›†ï¼Œæ¯”ä¾‹ä¸º 70% è®­ç»ƒï¼Œ30% æµ‹è¯•\n",
    "train, test = train_test_split(train1, test_size=0.3, random_state=2023)\n",
    "decision_tree3 = ID3_createTree2(train, feature_labels, test)\n",
    "\n",
    "# å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œåˆ†ç±»\n",
    "predicted_labels3 = classifytest(decision_tree3, feature_labels, test1)\n",
    "\n",
    "# è®¡ç®—å‡†ç¡®ç‡\n",
    "true_labels = test1.iloc[:, -1].tolist()  # çœŸå®æ ‡ç­¾\n",
    "accuracy = calculate_accuracy(predicted_labels3, true_labels)\n",
    "\n",
    "print(\"Accuracy 2.0:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C45_createTree2(dataframe, feature_labels, test_dataframe=None, pre_pruning=True, post_pruning=True):\n",
    "    class_list = dataframe.iloc[:, -1].tolist()\n",
    "\n",
    "    if len(set(class_list)) == 1:\n",
    "        return class_list[0]\n",
    "\n",
    "    if len(dataframe.columns) == 1:\n",
    "        return majority_vote(class_list)\n",
    "\n",
    "    best_feature = C45_chooseBestFeatureToSplit(dataframe)\n",
    "    C45_tree = {best_feature: {}}\n",
    "    unique_values = dataframe[best_feature].unique()\n",
    "\n",
    "    # é¢„å‰ªæé€»è¾‘\n",
    "    if pre_pruning and test_dataframe is not None:\n",
    "        leaf = majority_vote(class_list)\n",
    "        leaf_predictions = [leaf] * len(test_dataframe)\n",
    "        root_accuracy = calculate_accuracy(leaf_predictions, test_dataframe.iloc[:, -1].tolist())\n",
    "        split_accuracies = []\n",
    "\n",
    "        for value in unique_values:\n",
    "            sub_dataframe = split_dataframe(dataframe, best_feature, value)\n",
    "            sub_test_dataframe = split_dataframe(test_dataframe, best_feature, value)\n",
    "            if not sub_test_dataframe.empty:\n",
    "                sub_tree = C45_createTree2(sub_dataframe, feature_labels, sub_test_dataframe, pre_pruning, post_pruning)\n",
    "                sub_predictions = classifytest({best_feature: sub_tree}, feature_labels, sub_test_dataframe)\n",
    "                split_accuracies.append(calculate_accuracy(sub_predictions, sub_test_dataframe.iloc[:, -1].tolist()))\n",
    "\n",
    "        if split_accuracies and all(accuracy < root_accuracy for accuracy in split_accuracies):\n",
    "            print(\"å‘ç”Ÿé¢„å‰ªæå¤„ç†\")\n",
    "            return leaf\n",
    "\n",
    "    # æ„å»ºå­æ ‘\n",
    "    for value in unique_values:\n",
    "        sub_dataframe = split_dataframe(dataframe, best_feature, value)\n",
    "        if not sub_dataframe.empty:\n",
    "            sub_test_dataframe = split_dataframe(test_dataframe, best_feature, value) if test_dataframe is not None else None\n",
    "            C45_tree[best_feature][value] = C45_createTree2(sub_dataframe, feature_labels, sub_test_dataframe, pre_pruning, post_pruning)\n",
    "\n",
    "    # åå‰ªæé€»è¾‘\n",
    "    if post_pruning and test_dataframe is not None:\n",
    "        leaf = majority_vote(class_list)\n",
    "        tree_predictions = classifytest(C45_tree, feature_labels, test_dataframe)\n",
    "        tree_accuracy = calculate_accuracy(tree_predictions, test_dataframe.iloc[:, -1].tolist())\n",
    "        leaf_accuracy = calculate_accuracy([leaf] * len(test_dataframe), test_dataframe.iloc[:, -1].tolist())\n",
    "\n",
    "        if leaf_accuracy > tree_accuracy:\n",
    "            print(\"å‘ç”Ÿåå‰ªæå¤„ç†\")\n",
    "            return leaf\n",
    "\n",
    "    return C45_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4.5: Information Gain Ratio for feature 'è‰²æ³½': 0.152\n",
      "C4.5: Information Gain Ratio for feature 'æ ¹è’‚': 0.113\n",
      "C4.5: Information Gain Ratio for feature 'æ•²å£°': 0.118\n",
      "C4.5: Information Gain Ratio for feature 'çº¹ç†': 0.257\n",
      "C4.5: Information Gain Ratio for feature 'å¯†åº¦': 0.273\n",
      "å‘ç”Ÿåå‰ªæå¤„ç†\n",
      "Accuracy 2.0: 0.6\n"
     ]
    }
   ],
   "source": [
    "# æ„å»ºå†³ç­–æ ‘\n",
    "feature_labels = list(train2.columns)  # æ‰€æœ‰ç‰¹å¾çš„åˆ—å\n",
    "\n",
    "# åˆ†å‰²æ•°æ®é›†ï¼Œæ¯”ä¾‹ä¸º 70% è®­ç»ƒï¼Œ30% æµ‹è¯•\n",
    "trainc, testc = train_test_split(train2, test_size=0.3, random_state=2023)\n",
    "decision_tree4 = C45_createTree2(trainc, feature_labels, testc)\n",
    "\n",
    "# å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œåˆ†ç±»\n",
    "predicted_labels4 = classifytest(decision_tree4, feature_labels, test2)\n",
    "\n",
    "# è®¡ç®—å‡†ç¡®ç‡\n",
    "true_labels = test2.iloc[:, -1].tolist()  # çœŸå®æ ‡ç­¾\n",
    "accuracy = calculate_accuracy(predicted_labels4, true_labels)\n",
    "\n",
    "print(\"Accuracy 2.0:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆ†æ\n",
    "\n",
    "å¯ä»¥çœ‹åˆ°æˆ‘åœ¨åŠ å…¥é¢„å‰ªæå’Œåå‰ªæç­–ç•¥åID3å†³ç­–æ ‘å’ŒC45å†³ç­–æ ‘çš„åˆ†ç±»ç²¾åº¦å˜åŒ–å¦‚ä¸‹ï¼š\n",
    "- ID3å†³ç­–æ ‘ä»0.7æå‡åˆ°0.8\n",
    "- C45å†³ç­–æ ‘ä»0.6åˆ°0.6ï¼Œæ²¡æœ‰å˜åŒ–\n",
    "\n",
    "å¯¹äºID3å†³ç­–æ ‘ï¼Œæˆ‘é€šè¿‡æˆ‘åŠ å…¥çš„æ ‡è®°å‘ç°äº†ç»è¿‡äº†ä¸‰æ¬¡é¢„å‰ªæçš„å¤„ç†ï¼Œç²¾åº¦ä»0.7æå‡åˆ°0.8ï¼ŒæŸ¥çœ‹test1çš„æ•°é‡å¯ä»¥å‘ç°æ˜¯å¤šäº†ä¸€ä¸ªåˆ†ç±»æ­£ç¡®çš„æ•°æ®è¡Œï¼Œè¯´æ˜é¢„å‰ªæç¡®å®æå‡äº†å†³ç­–æ ‘çš„åˆ†ç±»æ•ˆæœï¼Œæœ‰æ•ˆåœ°é¿å…æ‰äº†è¿‡æ‹Ÿåˆçš„å‘ç”Ÿã€‚\n",
    "\n",
    "å¯¹äºC45å†³ç­–æ ‘ï¼Œæˆ‘é€šè¿‡æˆ‘åŠ å…¥çš„æ ‡è®°å‘ç°äº†ç»è¿‡äº†ä¸€æ¬¡åå‰ªæçš„å¤„ç†ï¼Œä½†æ˜¯ç²¾åº¦å¹¶æ²¡æœ‰å‘ç”Ÿå˜åŒ–ï¼Œè¿™é‡Œæˆ‘ä»”ç»†æ¢ç©¶è®¤ä¸ºæ˜¯ä¸æ•°æ®é‡æœ‰å…³ï¼Œåå‰ªæå¤„ç†æ˜¯æ•´ä¸ªå†³ç­–æ ‘æ„å»ºåè¿›è¡Œéå†æ¥è¿›è¡Œå‰ªæçš„ï¼Œæ‰€ä»¥ç†è®ºä¸Šæ˜¯å¯ä»¥å‰ªæ‰å¯èƒ½è¿‡æ‹Ÿåˆçš„å­æ ‘ï¼Œä½†æ˜¯è¿™é‡Œç²¾åº¦å¹¶æ²¡æœ‰å‘ç”Ÿå˜åŒ–ï¼Œæˆ‘è§‰å¾—æ˜¯ç”±äºtest2æ•°æ®é‡å¤ªå°ï¼Œtest2åªæœ‰5ä¸ªæ•°æ®è¡Œï¼Œå¶ç„¶æ€§å¤ªå¤§ï¼Œå¦‚æœæ•°æ®é‡è¶³å¤Ÿï¼Œå†³ç­–æ•ˆæœä¼šæœ‰æ˜æ˜¾çš„æå‡ã€‚\n",
    "\n",
    "é¢å¤–åˆ†æè¯´æ˜ï¼šå…¶å®åœ¨å®ç°åŠ å…¥é¢„å‰ªæå’Œåå‰ªæç®—æ³•åçš„ID3å’ŒC45å†³ç­–æ ‘çš„è®­ç»ƒé›†ç»„æˆå·²ç»å‘ç”Ÿäº†æ”¹å˜ï¼ŒåŸæ¥æ˜¯å®Œå…¨çš„ä¸€ä¸ªtrainå…¨ä½œä¸ºè®­ç»ƒé›†è¿›è¡Œå†³ç­–æ ‘çš„æ­å»ºï¼Œç°åœ¨æ˜¯å°†trainåˆ’åˆ†æˆäº†è®­ç»ƒå’Œæµ‹è¯•è¿›è¡Œå†³ç­–æ ‘æ„å»ºï¼Œæ‰€ä»¥å…¶å®è¿™å·²ç»ä¸æ˜¯ä¸€ä¸ªååˆ†å®Œç¾çš„æ§åˆ¶å˜é‡æ³•çš„å¯¹æ¯”äº†ã€‚è¿™é‡Œæˆ‘è¿˜è€ƒè™‘äº†å¦‚æœæˆ‘ä¿æŒtrainä¸å˜ï¼Œè€Œæ˜¯ä»testä¸­å–ä¸€éƒ¨åˆ†è¿‡æ¥è¿›è¡Œé¢„å‰ªæå’Œåå‰ªæçš„æµ‹è¯•ï¼Œä½†æ˜¯åæ¥æˆ‘å¦å®šäº†è¿™ç§æ€è·¯ï¼Œå› ä¸ºè¿™ä¼šåœ¨æµ‹è¯•é›†ä¸Šé€ æˆæ›´å¤§çš„åå·®ï¼Œæˆ‘ä¿è¯äº†åœ¨æµ‹è¯•çš„æ—¶å€™éƒ½ç”¨äº†ç»Ÿä¸€çš„æµ‹è¯•é›†ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
